{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa1a33d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14f1fb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"Desktop/DataNew\"\n",
    "CATEGORIES = [\"Objects\", \"Sea\"]\n",
    "\n",
    "training_data = []\n",
    "IMG_SIZE =124\n",
    "\n",
    "def create_training_data():\n",
    "    \n",
    "    for category in CATEGORIES:\n",
    "\n",
    "        path = os.path.join(DATADIR,category)  \n",
    "        class_num = CATEGORIES.index(category)  \n",
    "\n",
    "        for img in tqdm(os.listdir(path)):  \n",
    "            try:\n",
    "            \n",
    "                img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE )  \n",
    "    \n",
    "\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                training_data.append([new_array, class_num])\n",
    "            \n",
    "                rot = cv2.rotate(new_array, cv2.ROTATE_90_CLOCKWISE)\n",
    "                training_data.append([rot, class_num])\n",
    "                rot2 = cv2.rotate(new_array, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "                training_data.append([rot2, class_num])\n",
    "                rot3 = cv2.rotate(new_array, cv2.ROTATE_180)\n",
    "                training_data.append([rot3, class_num])\n",
    "            \n",
    "                flip1 = cv2.flip(new_array, 0)\n",
    "                training_data.append([flip1, class_num])\n",
    "                flip2 = cv2.flip(new_array, 1)\n",
    "                training_data.append([flip2, class_num])\n",
    "                flip3 = cv2.flip(new_array, -1)\n",
    "                training_data.append([flip3, class_num])\n",
    "            \n",
    "\n",
    "                blr = cv2.medianBlur(new_array,5)\n",
    "                training_data.append([blr, class_num])\n",
    "            \n",
    "                blur = cv2.GaussianBlur(new_array,(5,5),0)\n",
    "                training_data.append([blur, class_num])\n",
    "            \n",
    "                im = new_array\n",
    "                rows,cols = im.shape\n",
    "                M = np.float32([[1,0,25],[0,1,25]])\n",
    "                dst = cv2.warpAffine(im,M,(cols,rows))\n",
    "                training_data.append([dst, class_num])\n",
    "                \n",
    "                im = new_array\n",
    "                rows,cols = im.shape\n",
    "                M2 = np.float32([[1,0,25],[0,1,-25]])\n",
    "                dst2 = cv2.warpAffine(im,M2,(cols,rows))\n",
    "                training_data.append([dst2, class_num])\n",
    "                \n",
    "                im = new_array\n",
    "                rows,cols = im.shape\n",
    "                M3 = np.float32([[1,0,-25],[0,1,25]])\n",
    "                dst3 = cv2.warpAffine(im,M3,(cols,rows))\n",
    "                training_data.append([dst3, class_num])\n",
    "                \n",
    "                im = new_array\n",
    "                rows,cols = im.shape\n",
    "                M4 = np.float32([[1,0,-25],[0,1,-25]])\n",
    "                dst4 = cv2.warpAffine(im,M4,(cols,rows))\n",
    "                training_data.append([dst4, class_num])\n",
    "                \n",
    "                \n",
    "            except Exception as e: \n",
    "                pass\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81419ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 737/737 [00:03<00:00, 243.27it/s]\n",
      "100%|██████████| 774/774 [00:02<00:00, 301.67it/s]\n"
     ]
    }
   ],
   "source": [
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8284258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19604"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51b66206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f6d2429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for sample in training_data[:10]:\n",
    "    print(sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "456d0035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[110]\n",
      "   [107]\n",
      "   [105]\n",
      "   ...\n",
      "   [104]\n",
      "   [ 91]\n",
      "   [ 97]]\n",
      "\n",
      "  [[112]\n",
      "   [111]\n",
      "   [109]\n",
      "   ...\n",
      "   [113]\n",
      "   [113]\n",
      "   [104]]\n",
      "\n",
      "  [[120]\n",
      "   [120]\n",
      "   [121]\n",
      "   ...\n",
      "   [103]\n",
      "   [108]\n",
      "   [ 97]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[126]\n",
      "   [125]\n",
      "   [124]\n",
      "   ...\n",
      "   [104]\n",
      "   [100]\n",
      "   [105]]\n",
      "\n",
      "  [[130]\n",
      "   [130]\n",
      "   [129]\n",
      "   ...\n",
      "   [ 98]\n",
      "   [ 93]\n",
      "   [105]]\n",
      "\n",
      "  [[131]\n",
      "   [129]\n",
      "   [129]\n",
      "   ...\n",
      "   [ 92]\n",
      "   [ 93]\n",
      "   [ 95]]]]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features,label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "    \n",
    "\n",
    "print(X[0].reshape(-1, IMG_SIZE, IMG_SIZE, 1))\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2adbdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_out = open(\"X.pickle\",\"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\",\"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "689486f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4c0c676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in ./opt/anaconda3/lib/python3.8/site-packages (1.8.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.41.1)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.15.0)\n",
      "Requirement already satisfied: tensorboard<1.9.0,>=1.8.0 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.8.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.5.2)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: six>=1.10.0 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.20.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: html5lib==0.9999999 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow) (0.9999999)\n",
      "Requirement already satisfied: bleach==1.5.0 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow) (1.5.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow) (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38e38151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import datasets\n",
    "from tensorflow.python.keras.datasets import cifar10\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "X = X.astype('uint8')\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "X = X/200.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52822514",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#256\n",
    "model.add(Conv2D(64, (3, 3), input_shape=X.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())  \n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "839fa7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13722 samples, validate on 5882 samples\n",
      "Epoch 1/5\n",
      "13722/13722 [==============================] - 443s 32ms/step - loss: 0.5607 - acc: 0.6783 - val_loss: 0.3509 - val_acc: 0.8526\n",
      "Epoch 2/5\n",
      "13722/13722 [==============================] - 489s 36ms/step - loss: 0.3038 - acc: 0.8732 - val_loss: 0.2593 - val_acc: 0.8943\n",
      "Epoch 3/5\n",
      "13722/13722 [==============================] - 440s 32ms/step - loss: 0.2346 - acc: 0.9067 - val_loss: 0.2275 - val_acc: 0.9109\n",
      "Epoch 4/5\n",
      "13722/13722 [==============================] - 454s 33ms/step - loss: 0.1910 - acc: 0.9276 - val_loss: 0.1998 - val_acc: 0.9260\n",
      "Epoch 5/5\n",
      "13722/13722 [==============================] - 467s 34ms/step - loss: 0.1547 - acc: 0.9440 - val_loss: 0.2024 - val_acc: 0.9228\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x7fa211992430>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, np.array(y), batch_size=32, epochs=5,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba11618c",
   "metadata": {},
   "outputs": [],
   "source": [
    "   model.save('64x3-CNN.model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c37e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14fca112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "filepath = \"Desktop/DataTest\"\n",
    "CATEGORIES = [\"Objects\", \"Sea\"]  # will use this to convert prediction num to string value\n",
    "\n",
    "\n",
    "def prepare(filepath):\n",
    "    IMG_SIZE = 124  # 50 in txt-based\n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)  # read in the image, convert to grayscale\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize image to match model's expected sizing\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)  # return the image with shaping that TF wants.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "887014cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"64x3-CNN.model2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "969191db",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"Desktop/DataTest/Sea/images-4.jpg\"\n",
    "CATEGORIES = [\"Objects\", \"Sea\"] \n",
    "\n",
    "\n",
    "def prepare():\n",
    " # iterate over each image per dogs and cats\n",
    "                path = os.path.join(DATADIR)\n",
    "            #img_array = cv2.imread(os.path.join(path,img))\n",
    "                img_array = cv2.imread(os.path.join(path),cv2.IMREAD_GRAYSCALE )  # convert to array\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b07b2bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[213],\n",
       "         [200],\n",
       "         [209],\n",
       "         ...,\n",
       "         [217],\n",
       "         [236],\n",
       "         [237]],\n",
       "\n",
       "        [[204],\n",
       "         [208],\n",
       "         [206],\n",
       "         ...,\n",
       "         [172],\n",
       "         [197],\n",
       "         [193]],\n",
       "\n",
       "        [[201],\n",
       "         [183],\n",
       "         [180],\n",
       "         ...,\n",
       "         [211],\n",
       "         [212],\n",
       "         [211]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 59],\n",
       "         [ 62],\n",
       "         [ 58],\n",
       "         ...,\n",
       "         [ 45],\n",
       "         [ 51],\n",
       "         [ 53]],\n",
       "\n",
       "        [[ 62],\n",
       "         [ 68],\n",
       "         [ 65],\n",
       "         ...,\n",
       "         [ 52],\n",
       "         [ 52],\n",
       "         [ 52]],\n",
       "\n",
       "        [[ 66],\n",
       "         [ 69],\n",
       "         [ 65],\n",
       "         ...,\n",
       "         [ 59],\n",
       "         [ 52],\n",
       "         [ 52]]]], dtype=uint8)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "da800d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(prepare())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4e639485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "db628db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sea\n"
     ]
    }
   ],
   "source": [
    "print(CATEGORIES[int(prediction[0][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2858aaea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
